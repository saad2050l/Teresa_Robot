{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for the testing of the Teresa Robot\n",
    "## Importing all necessary tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EJt__rjLgh_P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: UserWarning: You do not have a working installation of the service_identity module: 'No module named 'service_identity''.  Please install it from <https://pypi.python.org/pypi/service_identity> and make sure all of its dependencies are satisfied.  Without the service_identity module, Twisted can perform only rudimentary TLS client hostname verification.  Many valid certificate/hostname mappings may be rejected.\n"
     ]
    }
   ],
   "source": [
    "import roslibpy # Communication with the HMI\n",
    "import time \n",
    "from src.gym_envs.RobotEnv_ import RobotEnv # Training environment\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import roslibpy # API of ROS\n",
    "from src.robots.Teresa_adap import Teresa # This is the representation of Teresa Robot\n",
    "from src.utils.training_tools import NB_STATES\n",
    "from src.robots.actions.camera_adap import DlinkDCSCamera # class for the camera\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym\n",
    "import cv2\n",
    "import logging\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the connection with ROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Bha-MkJ-gjKA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#ip_ordi : 192.168.1.50\n",
    "\n",
    "client = roslibpy.Ros(host=\"192.168.1.14\", port=9090)\n",
    "client.run()\n",
    "print(client.is_connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7jospMo1RQH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the connection with the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DayNightMode': '2',\n",
       " 'LightSensorControl': '3',\n",
       " 'IRLedScheduleSunStart': '00:00',\n",
       " 'IRLedScheduleSunEnd': '00:00',\n",
       " 'IRLedScheduleMonStart': '00:00',\n",
       " 'IRLedScheduleMonEnd': '00:00',\n",
       " 'IRLedScheduleTueStart': '00:00',\n",
       " 'IRLedScheduleTueEnd': '00:00',\n",
       " 'IRLedScheduleWedStart': '00:00',\n",
       " 'IRLedScheduleWedEnd': '00:00',\n",
       " 'IRLedScheduleThuStart': '00:00',\n",
       " 'IRLedScheduleThuEnd': '00:00',\n",
       " 'IRLedScheduleFriStart': '00:00',\n",
       " 'IRLedScheduleFriEnd': '00:00',\n",
       " 'IRLedScheduleSatStart': '00:00',\n",
       " 'IRLedScheduleSatEnd': '00:00'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host='192.168.1.35'\n",
    "user='admin'\n",
    "password='123456'\n",
    "\n",
    "camera = DlinkDCSCamera(host = host, user = user, password = password)\n",
    "\n",
    "camera.set_day_night(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-b374cf08b167>:51: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/crom/anaconda3/envs/venv/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NbStat = NB_STATES\n",
    "state_size = NbStat\n",
    "action_size = 4\n",
    "# new_graph = tf.Graph()\n",
    "initializer=tf.initializers.glorot_uniform()\n",
    "learning_rate = 0.01\n",
    "\n",
    "def discount_correct_rewards(r, gamma=0.99):\n",
    "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "  discounted_r = np.zeros_like(r)\n",
    "  running_add = 0\n",
    "  for t in reversed(range(0, r.size)):\n",
    "    #if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
    "    running_add = running_add * gamma + r[t]\n",
    "    discounted_r[t] = running_add\n",
    "\n",
    "  discounted_r -= discounted_r.mean()\n",
    "  discounted_r /- discounted_r.std()\n",
    "  return discounted_r\n",
    "\n",
    "def discount_and_normalize_rewards(episode_rewards):\n",
    "    discounted_episode_rewards = np.zeros_like(episode_rewards)\n",
    "    cumulative = 0.0\n",
    "    #print(\"len episode rewards\",episode_rewards)\n",
    "    for i in reversed(range(len(episode_rewards))):\n",
    "        cumulative = cumulative * gamma + episode_rewards[i]\n",
    "        #print(\"dans boucle\",episode_rewards[i],\"cyl\",cumulative)\n",
    "        discounted_episode_rewards[i] = cumulative\n",
    "    \n",
    "    mean = np.mean(discounted_episode_rewards)\n",
    "    std = np.std(discounted_episode_rewards)\n",
    "    if std :\n",
    "        discounted_episode_rewards = (discounted_episode_rewards - mean) / (std)\n",
    "    else:\n",
    "        discounted_episode=[]\n",
    "        discounted_episode_rewards[0] = np.array(mean)\n",
    "        print(\"ATTTTTTTTTTTTTTTTTT\")\n",
    "    #print(\"dis\",discounted_episode_rewards,\"std\",std)\n",
    "    \n",
    "    return discounted_episode_rewards\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    input_ = tf.placeholder(tf.float32, [None, state_size], name=\"input_\")\n",
    "    actions = tf.placeholder(tf.int32, [None, action_size], name=\"actions\")\n",
    "    discounted_episode_rewards_ = tf.placeholder(tf.float32, [None,], name=\"discounted_episode_rewards\")\n",
    "    \n",
    "    # Add this placeholder for having this variable in tensorboard\n",
    "    mean_reward_ = tf.placeholder(tf.float32 , name=\"mean_reward\")\n",
    "\n",
    "    with tf.name_scope(\"fc1\"):\n",
    "        fc1 = tf.layers.dense(input_ , 20, activation=tf.nn.relu,kernel_initializer=initializer)\n",
    "\n",
    "    with tf.name_scope(\"fc2\"):\n",
    "        fc2 = tf.layers.dense(fc1, action_size,activation= tf.nn.relu, kernel_initializer=initializer)\n",
    "    \n",
    "    with tf.name_scope(\"fc3\"):\n",
    "        fc3 = tf.layers.dense(fc2, action_size, activation= None,kernel_initializer=initializer)\n",
    "\n",
    "    with tf.name_scope(\"softmax\"):\n",
    "        action_distribution = tf.nn.softmax(fc3)\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        # tf.nn.softmax_cross_entropy_with_logits computes the cross entropy of the result after applying the softmax function\n",
    "        # If you have single-class labels, where an object can only belong to one class, you might now consider using \n",
    "        # tf.nn.sparse_softmax_cross_entropy_with_logits so that you don't have to convert your labels to a dense one-hot array. \n",
    "        neg_log_prob = tf.nn.softmax_cross_entropy_with_logits_v2(logits = fc3, labels = actions)\n",
    "        #loss = tf.nn.sparse_softmax_cross_entropy_with_logits (neg_log_prob * discounted_episode_rewards_)\n",
    "        loss = tf.reduce_mean(neg_log_prob * discounted_episode_rewards_) \n",
    "        \n",
    "    \n",
    "    with tf.name_scope(\"train\"):\n",
    "        train_opt = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "# Setup TensorBoard Writer\n",
    "\n",
    "\n",
    "## Losses\n",
    "## TRAINING Hyperparameters\n",
    "\n",
    "# tf.summary.scalar(\"Loss\", loss)\n",
    "\n",
    "# ## Reward mean\n",
    "# tf.summary.scalar(\"Reward_mean\", mean_reward_)\n",
    "\n",
    "max_episodes = 500\n",
    "\n",
    "gamma = 0.95 # Discount rate\n",
    "max_batch = NbStat*5\n",
    "    \n",
    "episode_rewards_sum = 0\n",
    "\n",
    "        # Launch the game\n",
    "    #state = env.reset()\n",
    "    #ne_state=np.identity(NbStat)[state:state+1]\n",
    "    #env.render()\n",
    "episode_length=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from pgpendul.ckpt\n",
      "None\n",
      "****************************************************\n",
      "EPISODE  0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 2582 action 1\n",
      "[[0.6123232  0.32291558 0.02432158 0.04043959]]\n",
      "state 2582 ne_state 2464 action 0\n",
      "[[9.7810441e-01 1.8232362e-02 3.1516841e-03 5.1155296e-04]]\n",
      "state 2464 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 2463 action 0\n",
      "[[0.66600144 0.28057677 0.02083562 0.03258613]]\n",
      "state 2463 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 350 action 0\n",
      "[[0.6390509  0.29762787 0.02482091 0.03850023]]\n",
      "state 350 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 3155 action 1\n",
      "[[0.66290593 0.28116426 0.02206603 0.03386375]]\n",
      "state 3155 ne_state 2680 action 1\n",
      "[[0.6040686  0.3405796  0.01925615 0.03609565]]\n",
      "state 2680 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 2804 action 1\n",
      "[[0.6572582  0.28527126 0.02260963 0.03486096]]\n",
      "state 2804 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 2224 action 0\n",
      "[[0.936974   0.04977546 0.01011111 0.00313943]]\n",
      "state 2224 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 1996 action 0\n",
      "[[0.46320212 0.4454152  0.02949817 0.06188448]]\n",
      "state 1996 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  2\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  3\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  4\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  5\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  6\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  7\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  8\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  9\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  10\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  11\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 1364 action 1\n",
      "[[0.6761306  0.27370358 0.01957029 0.0305956 ]]\n",
      "state 1364 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.46858507 0.45749405 0.02211777 0.05180315]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d0c2fd067549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# new_state, reward, done, info = env.step(int(action),True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/robot test/src/gym_envs/RobotEnv_.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# Boolean that indicates that an episode has finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_robot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Execute Move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Process image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mobject_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Define state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/robot test/src/robots/Robot_adap.py\u001b[0m in \u001b[0;36mmove_robot\u001b[0;34m(self, move)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \"\"\"\n\u001b[1;32m     42\u001b[0m         \u001b[0mexecute_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_topic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtake_picture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamera_topic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mremove_subscribers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/robot test/src/robots/actions/camera_adap.py\u001b[0m in \u001b[0;36mtake_picture\u001b[0;34m(camera_topic)\u001b[0m\n\u001b[1;32m    698\u001b[0m '''\n\u001b[1;32m    699\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtake_picture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_topic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0mcapture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://admin:123456@192.168.1.35:80/video/mjpg.cgi?profileid=1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#important\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m     \u001b[0mlargeur_capture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_FRAME_WIDTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0mhauteur_capture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_FRAME_HEIGHT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "client.run() # This run the main loop of ROS\n",
    "teresa_controller = Teresa(client) # Robot API\n",
    "env = RobotEnv(teresa_controller, client) # Training Environment\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # sess.run(tf.global_variables_initializer())\n",
    "   \n",
    "        # Load the model\n",
    "    print(saver.restore(sess, \"pgpendul.ckpt\"))\n",
    "    # if not saver.restore(sess, \"pgpendul.ckpt\"):\n",
    "    #     print()\n",
    "    total_rewards = 0\n",
    "    for episode in range(50):\n",
    "        state = env.reset()\n",
    "        #ne_state=np.identity(NbStat)[state:state+1]\n",
    "        step = 0\n",
    "        done = False\n",
    "        \n",
    "        print(\"****************************************************\")\n",
    "        print(\"EPISODE \", episode)\n",
    "\n",
    "       \n",
    "        #while True:\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < 500:\n",
    "            j+=1\n",
    "            state=int(state)\n",
    "            ne_state=np.identity(NbStat)[state:state+1]\n",
    "            # Choose action a, remember WE'RE NOT IN A DETERMINISTIC ENVIRONMENT, WE'RE OUTPUT PROBABILITIES.\n",
    "            action_probability_distribution = sess.run(action_distribution, feed_dict={input_: ne_state.reshape([1,NbStat])})\n",
    "            print(action_probability_distribution)\n",
    "            action = np.random.choice(range(action_probability_distribution.shape[1]), p=action_probability_distribution.ravel())  # select action w.r.t the actions prob\n",
    "            #action = np.argmax(action_probability_distribution)\n",
    "            \n",
    "\n",
    "            # new_state, reward, done, info = env.step(int(action),True)\n",
    "            new_state, reward, done, info = env.step(int(action))\n",
    "            env.render()\n",
    "\n",
    "            print(\"state\",state,\"ne_state\",new_state,\"action\",action) \n",
    "            total_rewards += reward\n",
    "            if done:    \n",
    "                #rewards.append(total_rewards)\n",
    "                print (\"Score\", total_rewards)\n",
    "                break\n",
    "            state = new_state\n",
    "    env.close()\n",
    "print (\"Score over time: \" ,  total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "robot_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}